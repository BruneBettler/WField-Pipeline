# Vanessa's Processing Pipeline

This folder contains the complete workflow for processing Widefield Calcium Imaging data, from raw frames to synchronized analysis.

## Pipeline Overview

The workflow consists of three main stages, which can be run individually or together using the master script or GUI.

### 0. GUI Launcher (Recommended)
The **Pipeline Launcher** allows you to select a parent directory, view all session folders, and process them in a batch.

```bash
python pipeline_launcher_gui.py
```

**Features:**
*   **Batch Selection**: Check multiple folders to run them sequentially.
*   **Draw Mask Button**: Open the masking GUI for a selected session.
    *   Works on **Preprocessed Data** (HDF5) OR **Raw Data** (.dat).
    *   If you draw the mask before running the pipeline, the pipeline will seamlessly use it without stopping.
*   **Progress Tracking**: Granular progress bars for the current session.
*   **Interactive Error Handling**: If a mask is missing during a run, the Launcher will pause and ask you to draw it, then retry the session automatically.

### 1. Master Script (CLI)
The easiest way to run the full analysis via command line is using `process_and_align.py`. This script orchestrates all steps in the correct order.

```bash
python process_and_align.py --data_dir "D:\Path\To\Experiment\Date_Folder"
```

**Options:**
*   `--skip_preprocessing`: Skip the raw frame processing steps.
*   `--skip_alignment`: Skip the signal synchronization steps.
*   `--skip_video`: Skip generating the verification video.

---

### 2. Individual Stages

You can also run each step independently if you need to debug or re-run a specific part.

#### Stage 1: Preprocessing
**Script:** `preprocessing_pipeline.py`
**Input:** Raw `.dat` frames
**Output:** `preprocessed_data/` (HDF5 file with motion corrected, hemo corrected, and dF/F data)

```bash
python preprocessing_pipeline.py --data_dir "D:\Path\To\Data"
```
*   **Key Action**: This step will launch a GUI asking you to draw a brain mask.

#### Stage 2: Alignment
**Script:** `alignment_pipeline.py`
**Input:** `Analog_1.dat` (Triggers) and `preprocessed_data/`
**Output:** `alignment/` (Contains `aligned_full_matrix.npy`, the master 10kHz timeline)

```bash
python alignment_pipeline.py --data_dir "D:\Path\To\Data"
```

#### Stage 3: Verification
**Script:** `generate_alignment_video.py`
**Input:** `alignment/aligned_full_matrix.npy`, `eyecam_*.mp4`, HDF5 dF/F
**Output:** `alignment_verification/alignment_side_by_side.mp4`

```bash
python generate_alignment_video.py --data_dir "D:\Path\To\Data"
```

## Directory Structure Expectations

The input directory should look like this before running:
```
Experiment_Date/
  ├── Frames_2_640_540_uint16_0000.dat  (Raw Video)
  ├── Analog_1.dat                      (Trigger Signals)
  └── eyecam_videofile.mp4              (Eye Camera)
```

After running `process_and_align.py`, it will look like this:
```
Experiment_Date/
  ├── Frames_...
  ├── Analog_...
  ├── eyecam_...
  ├── preprocessed_data/                (Generated by Stage 1)
  │   └── data.h5
  ├── alignment/                        (Generated by Stage 2)
  │   └── aligned_full_matrix.npy
  └── alignment_verification/           (Generated by Stage 3)
      └── alignment_side_by_side.mp4
```
